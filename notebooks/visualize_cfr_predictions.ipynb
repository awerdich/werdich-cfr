{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVAILABLE GPUs:\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')\n",
      "TRAIN DEVICE LIST:\n",
      "/GPU:0\n",
      "/GPU:1\n",
      "/GPU:2\n",
      "/GPU:3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Custom imports\n",
    "from werdich_cfr.models.Modeltrainer_Inc2 import VideoTrainer\n",
    "from werdich_cfr.tfutils.tfutils import use_gpu_devices\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "physical_devices, device_list = use_gpu_devices(gpu_device_string='0,1,2,3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint files from model_dir\n",
    "def get_checkpoint_file_list(model_dir, epoch_list):\n",
    "    \n",
    "    checkpoint_file_list = sorted(glob.glob(os.path.join(model_dir, '*_chkpt_*.h5')))\n",
    "    checkpoint_file_list_xt = [file.split('.')[0] for file in checkpoint_file_list]\n",
    "    checkpoint_file_cut = [file.rsplit('_', maxsplit=1)[0] for file in checkpoint_file_list_xt][0]\n",
    "    checkpoint_epoch_list = [int(os.path.basename(file).rsplit('_')[-1]) \\\n",
    "                             for file in checkpoint_file_list_xt]\n",
    "    mag=len(str(max(checkpoint_epoch_list)))\n",
    "\n",
    "    # Select only those epochs that we want\n",
    "    epoch_list = sorted(list(set(checkpoint_epoch_list).intersection(set(epoch_list))))\n",
    "    print(f'Found checkpoints for epochs: {epoch_list}')\n",
    "    epoch_checkpoint_file_list = [checkpoint_file_cut+'_'+str(epoch).zfill(mag)+'.h5' for epoch in epoch_list]\n",
    "    \n",
    "    return epoch_checkpoint_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/obi0/andreas/data/cfr/log/global_a4c_gpu2_global_cfr_calc/\n",
      "/mnt/obi0/andreas/data/cfr/log/nondefect_a4c_dgx-1_unaffected_cfr/\n",
      "/mnt/obi0/andreas/data/cfr/log/global_a4c_dgx-1_rest_global_mbf/\n",
      "/mnt/obi0/andreas/data/cfr/log/nondefect_a4c_dgx-1_stress_mbf_unaff/\n",
      "/mnt/obi0/andreas/data/cfr/log/global_a4c_gpu2_rest_global_mbf/\n",
      "/mnt/obi0/andreas/data/cfr/log/global_a4c_gpu2_fc128aug_rest_global_mbf/\n",
      "/mnt/obi0/andreas/data/cfr/log/nondefect_a4c_dgx-1_rest_mbf_unaff/\n",
      "/mnt/obi0/andreas/data/cfr/log/global_a4c_gpu2_fc128_rest_global_mbf/\n",
      "/mnt/obi0/andreas/data/cfr/log/global_a4c_gpu2_stress_global_mbf/\n",
      "/mnt/obi0/andreas/data/cfr/log/global_a4c_dgx-1_global_cfr_calc/\n",
      "/mnt/obi0/andreas/data/cfr/log/global_a4c_dgx-1_stress_global_mbf/\n"
     ]
    }
   ],
   "source": [
    "data_root = os.path.normpath('/mnt/obi0/andreas/data/cfr')\n",
    "log_dir = os.path.join(data_root, 'log')\n",
    "model_dir_list = glob.glob(os.path.join(log_dir, '*/'))\n",
    "print(*model_dir_list, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test files:\n",
      "/mnt/obi0/andreas/data/cfr/tfr_200519/global/cfr_global_a4c_test_200519_0.tfrecords\n",
      "/mnt/obi0/andreas/data/cfr/tfr_200519/global/cfr_global_a4c_test_200519_1.tfrecords\n",
      "/mnt/obi0/andreas/data/cfr/tfr_200519/global/cfr_global_a4c_test_200519_2.tfrecords\n",
      "/mnt/obi0/andreas/data/cfr/tfr_200519/global/cfr_global_a4c_test_200519_3.tfrecords\n",
      "/mnt/obi0/andreas/data/cfr/tfr_200519/global/cfr_global_a4c_test_200519_4.tfrecords\n",
      "/mnt/obi0/andreas/data/cfr/tfr_200519/global/cfr_global_a4c_test_200519_5.tfrecords\n",
      "/mnt/obi0/andreas/data/cfr/tfr_200519/global/cfr_global_a4c_test_200519_6.tfrecords\n",
      "/mnt/obi0/andreas/data/cfr/tfr_200519/global/cfr_global_a4c_test_200519_7.tfrecords\n",
      "Found checkpoints for epochs: [50, 100, 150]\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "model_dir = os.path.normpath(model_dir_list[0])\n",
    "\n",
    "epoch_list = [50, 100, 150]\n",
    "\n",
    "# This can be in a function\n",
    "\n",
    "model_dict_name = os.path.basename(model_dir)+'_model_dict.pkl'\n",
    "model_dict_file = os.path.join(model_dir, model_dict_name)\n",
    "train_dict_name = model_dict_name.replace('_model_dict.pkl', '_train_dict.pkl')\n",
    "train_dict_file = os.path.join(model_dir, train_dict_name)\n",
    "with open(model_dict_file, 'rb') as fl:\n",
    "    model_dict = pickle.load(fl)\n",
    "with open(train_dict_file, 'rb') as fl:\n",
    "    train_dict = pickle.load(fl)\n",
    "\n",
    "#test files\n",
    "train_file = train_dict['train_file_list'][0]\n",
    "test_basename = os.path.basename(train_file).rsplit('_', maxsplit=1)[0].replace('train', 'test')\n",
    "tfr_dir = os.path.dirname(train_file)\n",
    "test_tfr_file_list = sorted(glob.glob(os.path.join(tfr_dir, test_basename+'*.tfrecords')))\n",
    "test_parquet_file_list = [file.replace('.tfrecords', '.parquet') for file in test_tfr_file_list]\n",
    "test_df = pd.concat([pd.read_parquet(file) for file in test_parquet_file_list])\n",
    "print('Test files:')\n",
    "print(*test_tfr_file_list, sep='\\n')\n",
    "\n",
    "# feature_dict\n",
    "feature_dict_file = glob.glob(os.path.join(tfr_dir, '*.pkl'))[0]\n",
    "with open(feature_dict_file, 'rb') as fl:\n",
    "    feature_dict = pickle.load(fl)\n",
    "    \n",
    "# instantiate model trainer class\n",
    "VT = VideoTrainer(log_dir=None, model_dict=model_dict, train_dict=train_dict, feature_dict=feature_dict)\n",
    "    \n",
    "# checkpoint_files\n",
    "checkpoint_file_list = get_checkpoint_file_list(model_dir, epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting true labels from testset.\n",
      "Samples: 123, steps: 11\n",
      "11/11 [==============================] - 17s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "pred_df = VT.predict_on_test(test_tfr_file_list[0], checkpoint_file_list[0], batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_cfr_calc</th>\n",
       "      <th>global_a4c_gpu2_global_cfr_calc_chkpt_050</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.384252</td>\n",
       "      <td>2.044266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.742226</td>\n",
       "      <td>1.910853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994403</td>\n",
       "      <td>1.942179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.077720</td>\n",
       "      <td>1.986941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.888172</td>\n",
       "      <td>1.118363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_cfr_calc  global_a4c_gpu2_global_cfr_calc_chkpt_050\n",
       "0         2.384252                                   2.044266\n",
       "1         0.742226                                   1.910853\n",
       "2         0.994403                                   1.942179\n",
       "3         1.077720                                   1.986941\n",
       "4         0.888172                                   1.118363"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re_shape the output of the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'global_cfr_calc'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['model_output']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
